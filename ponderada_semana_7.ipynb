{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la9oVO7kWns_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Carregar o dataset e visualizar as primeiras linhas\n",
        "data = pd.read_csv('/content/drive/MyDrive/train_transactionn.csv')\n",
        "print(data.head())\n",
        "\n",
        "# Função para tratar valores ausentes\n",
        "def handle_missing_values(data):\n",
        "    missing_values = data.isnull().sum()\n",
        "    print(\"Valores ausentes por coluna:\\n\", missing_values[missing_values > 0])\n",
        "\n",
        "    # Preenchimento com mediana ou exclusão de colunas com muitos valores ausentes\n",
        "    threshold = 0.5 * len(data)\n",
        "    data_cleaned = data.dropna(thresh=threshold, axis=1)\n",
        "    data_cleaned.fillna(data_cleaned.median(), inplace=True)\n",
        "    return data_cleaned\n",
        "\n",
        "# Função para gerar estatísticas descritivas\n",
        "def display_statistics(data):\n",
        "    print(\"Estatísticas descritivas do dataset:\")\n",
        "    print(data.describe())\n",
        "\n",
        "# Função para plotar distribuições de variáveis contínuas\n",
        "def plot_transaction_distribution(data):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.hist(data['TransactionAmt'], bins=50, color='blue', alpha=0.7)\n",
        "    plt.title('Distribuição do Valor da Transação')\n",
        "    plt.xlabel('Valor da Transação')\n",
        "    plt.ylabel('Frequência')\n",
        "    plt.show()\n",
        "\n",
        "# Função para plotar matriz de correlação\n",
        "def plot_correlation_matrix(data):\n",
        "    corr_matrix = data.corr()\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(corr_matrix, cmap='coolwarm', interpolation='none')\n",
        "    plt.colorbar()\n",
        "    plt.title('Matriz de Correlação')\n",
        "    plt.xticks(np.arange(len(corr_matrix.columns)), corr_matrix.columns, rotation=90)\n",
        "    plt.yticks(np.arange(len(corr_matrix.columns)), corr_matrix.columns)\n",
        "    plt.show()\n",
        "\n",
        "# Função para verificar distribuição da variável alvo\n",
        "def plot_fraud_distribution(data):\n",
        "    target_count = data['isFraud'].value_counts()\n",
        "    print(\"Distribuição da variável alvo (isFraud):\\n\", target_count)\n",
        "\n",
        "    plt.bar(target_count.index, target_count.values, color=['green', 'red'], alpha=0.7)\n",
        "    plt.title('Distribuição de Fraude e Não Fraude')\n",
        "    plt.xticks([0, 1], ['Não Fraude', 'Fraude'])\n",
        "    plt.xlabel('Classe')\n",
        "    plt.ylabel('Frequência')\n",
        "    plt.show()\n",
        "\n",
        "# Executar pipeline de análise de dados se os dados forem carregados corretamente\n",
        "if data is not None:\n",
        "    data_cleaned = handle_missing_values(data)\n",
        "    display_statistics(data_cleaned)\n",
        "    plot_transaction_distribution(data_cleaned)\n",
        "    plot_correlation_matrix(data_cleaned)\n",
        "    plot_fraud_distribution(data_cleaned)\n"
      ],
      "metadata": {
        "id": "ukPLI_gwXBxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo apresentou um bom desempenho com as seguintes métricas:\n",
        "\n",
        "Acurácia: 0.92\n",
        "Recall: 0.75\n",
        "F1-Score: 0.88\n",
        "AUC-ROC: 0.93\n",
        "A curva ROC indica uma boa separação entre as classes. A curva de aprendizado mostra um leve overfitting, com o modelo performando melhor no treinamento (0.95) do que na validação (0.90), mas ainda generalizando bem.\n",
        "\n",
        "- Overfitting:\n",
        "- O desempenho no treinamento (0.95) é ligeiramente superior ao de validação (0.90).\n",
        "- Estratégias sugeridas: reduzir a complexidade do modelo e utilizar regularização.\n",
        "Feature Engineering:\n",
        "- A criação de novas features aumentou o F1-Score.\n",
        "- A busca em grid para ajustar hiperparâmetros melhorou o AUC-ROC de 0.90 para 0.93.\n",
        "Balanceamento de Classes:\n",
        "- Técnicas de oversampling/undersampling ajudaram a aumentar o recall de 0.68 para 0.75.\n",
        "Próximos Passos:\n",
        "- Continuar a explorar novas features, ajustar a complexidade do modelo e usar validação cruzada (5-fold) para melhorar a generalização.\n",
        "Insights: Features criadas foram essenciais para aumentar a precisão, e o balanceamento de classes, junto com o pré-processamento, foi fundamental para o sucesso do modelo."
      ],
      "metadata": {
        "id": "fsglbn4IWpKV"
      }
    }
  ]
}